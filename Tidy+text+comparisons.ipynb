{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tidy text comparisons\n",
    "This notebook was posted by Simon Lindgren // [@simonlindgren](http://www.twitter.com/simonlindgren) // [simonlindgren.com](http://simonlindgren.com)\n",
    "\n",
    "The code in this notebook helps with comparing two corpuses of texts to a third corpus. I call the latter the 'base' corpus, and the two others 'conservatives' and 'radicals' respectively.\n",
    "\n",
    "When creating this notebook, I drew heavily on [the book](http://tidytextmining.com/) by the creators of the `tidytext` package, and on [Julia Silge](https://twitter.com/juliasilge)'s amazing blog post on [The Life-Changing Magic of Tidying Text](http://juliasilge.com/blog/Life-Changing-Magic/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing the corpuses\n",
    "\n",
    "First, we read and tidyfy the three corpuses. Make sure that the `csv`'s are prepared correctly. It is a working minimum that they contain one column each with `text` as the header. If you have messy social media text, the characters `;` and `\"` often raise problems, so remove those. For all other details about these initial steps, see this [other notebook](https://github.com/simonlindgren/Tidy-Text-first-steps/blob/master/Tidy%2Btext%2Bfirst%2Bsteps.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(tidytext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create custom stop word list\n",
    "my_stop_words <- read_csv2(\"swestop.csv\")\n",
    "#my_stop_words <- read_csv2(\"swestop_custom.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing documents\n",
    "##### First corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our base corpus (that we want to compare the others to)\n",
    "# read it, tidy it\n",
    "base <- read_csv2(\"base.csv\")\n",
    "tidy_base <- base %>%\n",
    "    unnest_tokens(word,text)\n",
    "    #unnest_tokens(ngram, text, token = \"ngrams\", n = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove built in English stop words\n",
    "data(stop_words)\n",
    "tidy_base <- anti_join(tidy_base, stop_words, by=\"word\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove custom stop words\n",
    "tidy_base <- anti_join(tidy_base, my_stop_words, by=\"word\")\n",
    "tidy_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Second corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radicals <- read_csv2(\"radicals.csv\")\n",
    "tidy_radicals <- radicals %>%\n",
    "    unnest_tokens(word,text)\n",
    "    #unnest_tokens(ngram, text, token = \"ngrams\", n = 2)\n",
    "\n",
    "data(stop_words)\n",
    "tidy_radicals <- anti_join(tidy_radicals, stop_words, by=\"word\")\n",
    "tidy_radicals <- anti_join(tidy_radicals, my_stop_words, by=\"word\")\n",
    "tidy_radicals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Third corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conservatives <- read_csv2(\"conservatives.csv\")\n",
    "tidy_conservatives <- conservatives %>%\n",
    "    unnest_tokens(word,text)\n",
    "    #unnest_tokens(ngram, text, token = \"ngrams\", n = 2)\n",
    "\n",
    "data(stop_words)\n",
    "tidy_conservatives <- anti_join(tidy_conservatives, stop_words, by=\"word\")\n",
    "tidy_conservatives <- anti_join(tidy_conservatives, my_stop_words, by=\"word\")\n",
    "tidy_conservatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy_base %>%\n",
    "    count(word, sort = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check countz\n",
    "tidy_radicals %>%\n",
    "  count(word, sort = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy_conservatives %>%\n",
    "  count(word, sort = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bind corpus two and three together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(stringr)\n",
    "\n",
    "tidy_both <- bind_rows(\n",
    "        mutate(tidy_radicals, author=\"Radicals\"),\n",
    "        mutate(tidy_conservatives, author=\"Conservatives\"))\n",
    "tidy_both"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate frequencies for all three\n",
    "The next two chunks of code are _definitely_ courtesy of [Julia Silge](http://juliasilge.com/blog/Life-Changing-Magic/)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frequency <- tidy_both %>%\n",
    "    mutate(word = str_extract(word, \"[a-z]+\")) %>%\n",
    "    count(author, word) %>%\n",
    "    rename(other = n) %>%\n",
    "    inner_join(count(tidy_both, word)) %>%\n",
    "    rename(Base = n) %>%\n",
    "    mutate (other = other / sum(other), Base = Base/sum(Base)) %>%\n",
    "    ungroup()\n",
    "frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plot it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "library(scales)\n",
    "\n",
    "ggplot(frequency, aes(x = other, y = Base, color = abs(Base - other))) +\n",
    "        geom_abline(color = \"gray40\") +\n",
    "        geom_jitter(alpha = 0.1, size = 2.5, width = 0.4, height = 0.4) +\n",
    "        geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +\n",
    "        scale_x_log10(labels = percent_format()) +\n",
    "        scale_y_log10(labels = percent_format()) +\n",
    "        scale_color_gradient(limits = c(0, 0.001), low = \"darkslategray4\", high = \"gray75\") +\n",
    "        facet_wrap(~author, ncol = 2) +\n",
    "        theme_minimal(base_size = 14) +\n",
    "        theme(legend.position=\"none\") +\n",
    "        labs(title = \"Title of graph\",\n",
    "             subtitle = \"Subtitle of graph\",\n",
    "             y = \"Base\", x = NULL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Interpreting the plots\n",
    "- Words that are close to the line in these plots have similar frequencies in both sets of texts.\n",
    "- Words that are far from the line are words that are found more in one set of texts than another. \n",
    "\n",
    "(The percent frequencies for individual words are different in one plot when compared to another because of the inner join; not all the words are found in all three sets of texts so the percent frequency is a different quantity.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Correlation test\n",
    "Letâ€™s quantify how similar and different these sets of word frequencies are using a correlation test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cor.test(data = frequency[frequency$author == \"Conservatives\",], ~ other + Base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cor.test(data = frequency[frequency$author == \"Radicals\",], ~ other + Base)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
